---
title: "Results comparison"
output: html_notebook
---

## Setup

```{r setup, include=FALSE}
require(knitr)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = file.path(getwd(), '..')) # Project dir
# Note that below isn't currently working when running chunks interactively,
# but should when the document is knit
# https://github.com/rstudio/rstudio/issues/8149
# knitr::opts_chunk$set(engine.opts = list(bash = "-l"))
```

```{r}
# Load required R libraries
library(Biostrings)
library(here)
library(phyloseq)
library(qiime2R)
library(tidyverse)
```

## Read in data

```{r}
# Point to directory containing FASTQs at each stage

dcc.dir <- 
     here('data',
          'Adult-2',
          'prior')

qiime.dir <- 
     here('data',
          'Adult-2',
          'current')
```

```{r}
# Well to sample name mapping for prior data
# Batch 1, prior data
batch1.map <- 
     here('..',
          'onr',
          'data',
          'processed',
          'miniseq',
          '20201128',
          '20201128_sample_sheet.csv') %>% 
     read_csv(skip = 16) %>% 
     select(well = Sample_ID, sample = Name)

head(batch1.map)
```

### Read counts

```{r}
# Read in count files from DCC pipeline: Batch 1
count.fs <- list.files(dcc.dir, 
                       pattern = glob2rx('20201128*.txt'),
                       full.names = TRUE)

# Read them
count.fs <- lapply(count.fs, MButils::parse_counts)

# Bind into shared dataframe
counts.batch1 <- 
     reduce(count.fs, left_join, by = 'sample')

names(counts.batch1) <- c('sample', 
                         'raw', 
                         'adapter_trim',
                         'primer_filter',
                         'primer_trim')

rm(count.fs)
```

```{r}
# Batch 2
count.fs <- list.files(dcc.dir, 
                       pattern = glob2rx('20210105*.txt'),
                       full.names = TRUE)

# Read them
count.fs <- lapply(count.fs, MButils::parse_counts)

# Bind into shared dataframe
counts.batch2 <- 
     reduce(count.fs, left_join, by = 'sample')

names(counts.batch2) <- c('sample', 
                          'raw', 
                          'adapter_trim',
                          'primer_filter',
                          'primer_trim')

rm(count.fs)
```

```{r}
# Bind together
counts.batch1$batch <- '20201128'
counts.batch2$batch <- '20210105'

counts.prior <- 
     bind_rows(counts.batch1,
               counts.batch2)
```


```{bash engine.opts='-l'}
# Extract count information from QIIME2 visualization object
# Unzip the files if not already done
cd "$QIIME_DIR"

for f in *.qzv; do
     unzip $f -d ${f%.qzv}
done
```

```{r}
# Read TSVs
count.fs <- 
     list.files(qiime.dir,
                pattern = 'per-sample-fastq-counts.tsv',
                recursive = TRUE,
                full.names = TRUE)

count.fs <- 
     lapply(count.fs, read_delim) %>% 
     lapply(select, -`reverse sequence count`)

counts.qiime <- reduce(count.fs, left_join, by = 'sample ID')
names(counts.qiime) <- c('sample', 
                         'raw',
                         'adapter_trim',
                         'primer_trim')

rm(count.fs)
```

### Files

#### Adapter trimmed

```{r}
# Read in one file and do a side-by-side comparison: 
# What's the extent of differences?
dcc.atrim.fs <- 
     file.path(dcc.dir,
               '1_trimadapter') %>% 
     list.files(pattern = '*fastq.gz',
                full.names = TRUE)
```

```{bash engine.opts='-l'}
# First need to unzip all these
cd "$QIIME_DIR"
unzip 1_demultiplexed.qza -d 1_demultiplexed_fastq
unzip 2_adapter-trimmed.qza -d 2_adapter-trimmed_fastq
unzip 3_primer-trimmed.qza -d 3_primer-trimmed_fastq
```

```{r}
qiime.atrim.fs <- 
     here(qiime.dir,
          '2_adapter-trimmed_fastq',
          '4ed2f742-3915-4cd4-ae4e-1b74a5a6364d',
          'data') %>% 
     list.files(pattern = '*fastq.gz',
                full.names = TRUE)
```

#### Primer trimmed

```{r}
# Read in one file and do a side-by-side comparison: 
# What's the extent of differences?
dcc.ptrim.fs <- 
     file.path(dcc.dir,
               '3_trimprimer') %>% 
     list.files(pattern = '*fastq.gz',
                full.names = TRUE)
```

```{r}
qiime.ptrim.fs <- 
     here(qiime.dir,
          '3_primer-trimmed-direct_fastq',
          '8aa62d5a-773d-4407-ba64-4b288306f9f8',
          'data') %>% 
     list.files(pattern = '*fastq.gz',
                full.names = TRUE)
```


#### Sequence tables

Use QIIME2R functions to extract information from QIIME2 artifacts. 

```{r}
qiime.asvtab.1 <- 
     here(qiime.dir,
          'batch1',
          '4_denoised-table.qza') %>% 
     read_qza()

qiime.asvtab.2 <- 
     here(qiime.dir,
          'batch2',
          '4_denoised-table.qza') %>% 
     read_qza()
```

```{r}
qiime.seqs.1 <- 
     here(qiime.dir,
          'batch1',
          '4_denoised-seqs.qza') %>% 
     read_qza()

qiime.seqs.2 <- 
     here(qiime.dir,
          'batch2',
          '4_denoised-seqs.qza') %>% 
     read_qza()
```

```{r}
dcc.asvtab.1 <- 
     here(dcc.dir,
          '20201128_seqtab_nochim.rds') %>% 
     readRDS()

dcc.asvtab.2 <- 
     here(dcc.dir,
          '20210105_seqtab_nochim.rds') %>% 
     readRDS()
```

### Scripts

```{r}
# Helper script for calculating MD5 checksum on each gzipped FASTQ in directory
md5 <- 
     here('code', 
          'hash-fastqs')

Sys.setenv(MD5HELPER = md5)
```

## Pre-process

### Make phyloseq object

### Combine read counts
```{r}
# Provenance of read counts
counts.qiime$pipeline <- 'QIIME2'
counts.prior$pipeline <- 'DCC'
```

```{r}
# Combine
reads <- 
     bind_rows(counts.prior,
               counts.qiime)

reads
```

### Pipeline outputs

#### ASV tables

##### Prior

```{r}
# Rename Batch 1 samples for consistency
```

###### Current 
```{r}
# Map QIIME2 onto DCC format (samples x ASVs)
head(qiime.asvtab)
```
```{r}
qiime.asvtab <-
     qiime.asvtab %>% 
     left_join(qiime.asvs, 
               by = c('#OTU ID' = 'hash')) %>% 
     select(-`#OTU ID`) %>% 
     column_to_rownames(var = 'seq') %>% 
     t() %>% 
     data.frame()

qiime.asvtab
```


## Compare
